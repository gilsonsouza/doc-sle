<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>

<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="cha.boot">
 <title>Introduction to the Booting Process</title>
 <info>
  <abstract>
   <para>
    Booting a Linux system involves different components and tasks. After a
    firmware and hardware initialization process, which depends on the machine's
    architecture, the Kernel ist started by means of the boot loader
    &grub;. After this point, the boot process is completely controlled by the
    operating system and handled by &systemd;.  &systemd; provides a set of
    <quote>targets</quote> that boot setups for everyday usage, maintenance or
    emergencies.
   </para>
  </abstract>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>

 <sect1 xml:id="sec.boot.proc">
  <title>The Linux Boot Process</title>

  <para>
   The Linux boot process consists of several stages, each represented by a
   different component:
  </para>
  <orderedlist>
   <listitem>
    <para>
     <xref linkend="sec.boot.proc.initialization" xrefstyle="HeadingOnPage"/>
    </para>
   </listitem>
  </orderedlist>


  <sect2 xml:id="sec.boot.proc.initialization">
   <title>
    The Initialization and Boot Loader Phase
   </title>
   <para>
    During the initialization phase the machine's hardware is set up and the
    devices are prepared. This process differs significantly between hardware
    architectures.
   </para>
   <para>
    &productname; uses the boot loader &grub; on all architectures. Depending
    on the architecture and firmware, starting the &grub; boot loader can be a
    multi-step process. The purpose of the boot loader is to load the Kernel
    and the initial, RAM-based file system (initramfs). For more information
    about &grub;, refer to <xref linkend="cha.grub"/>.
   </para>
   <sect3 xml:id="sec.boot.proc.initialization.x86_aarch" arch="x86-64;aarch64">
    <title>
     Initialization and Boot Loader Phase on &aarch64; and &x86-64;
    </title>
    <para>
     After turning on the computer, the BIOS or the UEFI initializes the screen
     and keyboard, and tests the main memory. Up to this stage, the machine
     does not access any mass storage media. Subsequently, the information
     about the current date, time, and the most important peripherals are
     loaded from the CMOS values. When the boot media and its geometry are
     recognized, the system control passes from the BIOS/UEFI to the boot
     loader.
    </para>
    <para os="x86-64">
     On a machine equipped with a traditional BIOS (or when using the BIOS
     compatibility mode with UEFI), only code from the first physical 512-byte
     data sector (the Master Boot Record, MBR) of the boot disk can be
     loaded. Ther. It's sole purpose of the stage 1 &grub; is to load stage 1.5
     from the space between the MBR and the first partition. &grub; stage 1.5
     contains file system drivers and therefore is able to access
     <filename>/boot</filename> located on the root file system. This directory
     contains all files for &grub; stage 2, including the Kernel and the
     initramfs image. &grub; stage 1.5 loads &grub; stage 2 into memory and
     executes stage 2, the final stage of the boot loader. The purpose of this
     stage is to load the Kernel and the initramfs image into memory and hand
     control over to the Kernel.
    </para>
    <para>
     On machines with UEFI the boot process the boot process is much simpler
     than on machines with a traditional BIOS. The firmware is capable to read
     from a FAT formatted system partition of disks with a GPT partition
     table. This EFI system-partition (in the running system mounted as
     <filename>/boot/efi</filename>) holds enough space to host a fully-fledged
     &grub; which is directly loaded and executed by the firmware.
    </para>
    <para>
     If the BIOS/UEFI supports network booting, it is also possible to
     configure a boot server that provides the boot loader. The system can then
     be booted via PXE. the BIOS/uEFI acts as the boot loader. It gets the boot
     image from the boot server and starts the system. This is completely
     independent of local hard disks.
    </para>
   </sect3>
   <sect3 xml:id="sec.boot.proc.initialization.zsystems" arch="zseries">
    <title>
     Initialization and Boot Loader Phase on IBM &zseries;
    </title>
    <para>
     On IBM &zseries; the boot process must be initialized by a boot loader
     called <command>zipl</command> (z initial program load). Although
     <command>zipl</command> supports reading from various file systems, it
     does not suppport the &slea; default file system or booting from
     snapshots. &productname; therefore uses a two-stage boot process that
     ensures full Btrfs-support at boot-time:
    </para>
    <procedure>
     <step>
      <para>
       <command>zipl</command> boots from the ext2-formatted partition
       <filename>/boot/zipl</filename>. This partition contains a minimal
       Kernel and an initramfs images that are loaded into memory. The
       initramfs contains a Btrfs driver (among others) and the boot loader
       &grub;. The Kernel is started with a parameter
       <literal>initgrub</literal>, that tells it to start &grub;.
      </para>
     </step>
     <step>
      <para>
       The Kernel mounts the root file system, so <filename>/boot</filename>
       becomes accessible. Now &grub; is started from the initramfs. It reads
       it's configuration from <filename>/boot/grub2/grub.cfg</filename> and
       loads the final Kernel and initramfs from
       <filename>/boot</filename>. The new Kernel now gets loaded via &kexec;.
      </para>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.boot.proc.kernel">
   <title>The Kernel init Phase</title>
   <para>
    Once the boot loader has passed on system control, the boot process is the
    same on all architectures. The boot loader loads both the Kernel and an
    initaial RAM-based file system (<systemitem>initramfs</systemitem>) into
    memory. The contents of the <systemitem>initramfs</systemitem> can be used
    by the Kernel directly.
   </para>
   <para>
    <systemitem>initramfs</systemitem> contains a small executable called
    &systemd;. This program performs all actions needed to mount the proper
    root file system. It provides Kernel functionality for the needed file
    system and device drivers for mass storage controllers with <systemitem
    class="service">udev</systemitem>. After the root file system has been
    found, it is checked for errors and mounted. If this is successful, the
    <systemitem>initramfs</systemitem> is cleaned and the &systemd; daemon on
    the root file system is executed. &systemd; now starts all other system
    services. See <xref linkend="cha.systemd"/> for details.
   </para>
   <para>
    If special hardware drivers are needed before the mass storage can be
    accessed, they must be in <systemitem>initramfs</systemitem>. If the system
    does not have a local hard disk, the <systemitem>initramfs</systemitem>
    must provide the root file system for the Kernel. This can be done using a
    network block device like iSCSI or SAN, but it is also possible to use NFS
    as the root device.
   </para>
   <para>
    If the root file system fails to mount from within the boot environment, it
    must be checked and repaired before the boot can continue. The file system
    checker will be automatically started for Ext3 and Ext4 file systems. The
    repair process is not automated for XFS and Btrfs file systems, and the
    user is be presented with information describing the options available to
    repair the file system. When the file system has been successfully
    repaired, exiting the boot environment will cause the system to retry
    mounting the root file system. If successful, the boot will continue
    normally.
   </para>
  </sect2>



  <note>
     <title>The <systemitem>init</systemitem> Process Naming</title>
     <para>
      Two different programs are commonly named <quote>init</quote>:
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        the <systemitem>initramfs</systemitem> process mounting the root file
        system
       </para>
      </listitem>
      <listitem>
       <para>
        the operating system process setting up the system
       </para>
      </listitem>
     </orderedlist>
     <para>
      In this chapter we will therefore refer to them as
      <quote><systemitem>init</systemitem> on
      <systemitem>initramfs</systemitem></quote> and <quote>&systemd;</quote>,
      respectively.
     </para>
    </note>
   </listitem>
   <listitem>
    <formalpara>
     <title><systemitem>init</systemitem> on <systemitem>initramfs</systemitem></title>
     <para>
      This program performs all actions needed to mount the proper root file
      system. It provides Kernel functionality for the needed file system and
      device drivers for mass storage controllers with
      <systemitem class="service">udev</systemitem>. After the root file system
      has been found, it is checked for errors and mounted. If this is
      successful, the <systemitem>initramfs</systemitem> is cleaned and the
      &systemd; daemon on the root file system is executed. For more
      information about <systemitem>init</systemitem> on
      <systemitem>initramfs</systemitem>, refer to
      <xref linkend="sec.boot.linuxrc"/>. Find more information about
      <systemitem class="service">udev</systemitem> in
      <xref linkend="cha.udev"/>.
     </para>
    </formalpara>
   </listitem>

 <sect1 xml:id="sec.boot.initrd">
  <title><systemitem>initramfs</systemitem></title>

  <para>
   <systemitem>initramfs</systemitem> is a small cpio archive that the Kernel
   can load into a RAM disk. It provides a minimal Linux environment that
   enables the execution of programs before the actual root file system is
   mounted. This minimal Linux environment is loaded into memory by BIOS or
   UEFI routines and does not have specific hardware requirements other than
   sufficient memory. The <systemitem>initramfs</systemitem> archive must
   always provide an executable named <systemitem>init</systemitem> that
   executes the &systemd; daemon on the root file system for the boot process
   to proceed.
  </para>

  <para>
   Before the root file system can be mounted and the operating system can be
   started, the Kernel needs the corresponding drivers to access the device on
   which the root file system is located. These drivers may include special
   drivers for certain kinds of hard disks or even network drivers to access a
   network file system. The needed modules for the root file system may be
   loaded by <systemitem>init</systemitem> on
   <systemitem>initramfs</systemitem>. After the modules are loaded,
   <systemitem class="service">udev</systemitem> provides the
   <systemitem>initramfs</systemitem> with the needed devices. Later in the
   boot process, after changing the root file system, it is necessary to
   regenerate the devices. This is done by the &systemd; unit
   <filename>systemd-udev-trigger.service</filename> with the command
   <command>udevtrigger</command>.
  </para>

  <para>
   If you need to change hardware (for example, hard disks), and this hardware requires different drivers to be in the Kernel at
   boot time, you must update the <systemitem>initramfs</systemitem> file. This
   is done by calling <command>dracut</command> <option>-f</option> (the option
   <option>-f</option> overwrites the existing initramfs file). To add a driver
   for the new hardware, edit
   <filename>/etc/dracut.conf.d/01-dist.conf</filename> and add the following
   line.
  </para>

<screen>force_drivers+="<replaceable>DRIVER1</replaceable>"</screen>

  <para>
   Replace <replaceable>DRIVER1</replaceable> with the module name of the
   driver. If you need to add more than one driver, list them space-separated
   (<literal><replaceable>DRIVER1</replaceable>
   <replaceable>DRIVER2</replaceable></literal>).
  </para>

  <important>
   <title>Updating <systemitem>initramfs</systemitem> or <systemitem>init</systemitem></title>
   <para>
    The boot loader loads <systemitem>initramfs</systemitem> or
    <systemitem>init</systemitem> in the same way as the Kernel. It is not
    necessary to re-install &grub; after updating
    <systemitem>initramfs</systemitem> or <systemitem>init</systemitem>,
    because &grub; searches the directory for the right file when booting.
   </para>
  </important>

  <tip>
   <title>Changing Kernel Variables</title>
   <para>
    If you change the values of Kernel variables via the
    <command>sysctl</command> interface by editing related files
    (<filename>/etc/sysctl.conf</filename> or
    <filename>/etc/sysctl.d/*.conf</filename>), the change will be lost on the
    next system reboot. Even if you load the values with <command>sysctl
    --system</command> at runtime, the changes are not saved into the initramfs
    file. You need to update it by calling <command>dracut</command>
    <option>-f</option> (the option <option>-f</option> overwrites the existing
    initramfs file).
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="sec.boot.linuxrc">
  <title>Init on <systemitem>initramfs</systemitem></title>

  <para>
   The main purpose of <systemitem>init</systemitem> on
   <systemitem>initramfs</systemitem> is to prepare the mounting of and access
   to the real root file system. Depending on your system configuration,
   <systemitem>init</systemitem> on <systemitem>initramfs</systemitem> is
   responsible for the following tasks.
  </para>

  <variablelist>
   <varlistentry>
    <term>Loading Kernel Modules</term>
    <listitem>
     <para>
      Depending on your hardware configuration, special drivers may be needed
      to access the hardware components of your computer (the most important
      component being your hard disk). To access the final root file system,
      the Kernel needs to load the proper file system drivers.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Providing Block Special Files</term>
    <listitem>
     <para>
      The Kernel generates device events depending on loaded modules.
      <systemitem class="service">udev</systemitem> handles these events and
      generates the required special block files on a RAM file system in
      <filename>/dev</filename>. Without those special files, the file system
      and other devices would not be accessible.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Managing RAID and LVM Setups</term>
    <listitem>
     <para>
      If you configured your system to hold the root file system under RAID or
      LVM, <systemitem>init</systemitem> on <systemitem>initramfs</systemitem>
      sets up LVM or RAID to enable access to the root file system later.
     </para>
     <para>
      To change your <filename>/usr</filename> or
      <systemitem>swap</systemitem> partitions directly without the help of
      &yast;, further actions are needed. If you forget these steps, your
      system will start in emergency mode. To avoid starting in emergency mode,
      perform the following steps:
     </para>
     <procedure xml:id="pro.boot.linuxrc.lvm">
      <title>Updating Init RAM Disk When Switching to Logical Volumes</title>
      <step>
       <para>
        Edit the corresponding entry in <filename>/etc/fstab</filename> and
        replace your previous partitions with the logical volume.
       </para>
      </step>
      <step>
       <para>
        Execute the following commands:
       </para>
<screen>&prompt.root;<command>mount</command> -a
&prompt.root;<command>swapon</command> -a</screen>
      </step>
      <step>
       <para>
        Regenerate your initial RAM disk (initramfs) with
        <command>mkinitrd</command> or <command>dracut</command>.
       </para>
      </step>
      <step>
       <para>
        For &zseries;, additionally run <command>grub2-install</command>.
       </para>
      </step>
     </procedure>
     <para>
      Find more information about RAID and LVM in
      <xref
              linkend="cha.advdisk"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry xml:id="ve.net">
    <term>Managing Network Configuration</term>
    <listitem>
     <para>
      If you configured your system to use a network-mounted root file system
      (mounted via NFS), <systemitem>init</systemitem> on
      <systemitem>initramfs</systemitem> must make sure that the proper network
      drivers are loaded and that they are set up to allow access to the root
      file system.
     </para>
     <para>
      If the file system resides on a network block device like iSCSI or SAN,
      the connection to the storage server is also set up by
      <systemitem>init</systemitem> on <systemitem>initramfs</systemitem>.
      &productname; supports booting from a secondary iSCSI target if the
      primary target is not available. <phrase os="sles">For more details
      regarding configuration of the booting iSCSI target refer to
      <xref linkend="sec.iscsi.initiator.yast"/></phrase>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   When <systemitem>init</systemitem> on <systemitem>initramfs</systemitem> is
   called during the initial boot as part of the installation process, its
   tasks differ from those mentioned above:
  </para>

  <variablelist>
   <varlistentry>
    <term>Finding the Installation Medium</term>
    <listitem>
     <para>
      When starting the installation process, your machine loads an
      installation Kernel and a special <systemitem>init</systemitem>
      containing the &yast; installer. The &yast; installer is running in a RAM
      file system and needs to have information about the location of the
      installation medium to access it for installing the operating system.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>
      Initiating Hardware Recognition and Loading Appropriate Kernel Modules
     </term>
    <listitem>
     <para>
      As mentioned in <xref linkend="sec.boot.initrd"/>, the boot process
      starts with a minimum set of drivers that can be used with most hardware
      configurations. <systemitem>init</systemitem> starts an initial hardware
      scanning process that determines the set of drivers suitable for your
      hardware configuration. These drivers are used to generate a custom
      <systemitem>initramfs</systemitem> that is needed to boot the system. If
      the modules are not needed for boot but for coldplug, the modules can be
      loaded with &systemd;; for more information, see
      <xref linkend="sec.boot.systemd.advanced.kernel_modules"/>.
<!-- 2014-08-20, tiwai pointed out that
       <filename>/etc/sysconfig/hardware/hwconfig-*</filename> does not
       seem to be supported any longer. -->
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Loading the Installation System</term>
    <listitem>
     <para>
      When the hardware is properly recognized, the appropriate drivers are
      loaded. The <systemitem class="service">udev</systemitem> program creates
      the special device files and <systemitem>init</systemitem> starts the
      installation system with the &yast; installer.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Starting &yast;</term>
    <listitem>
     <para>
      Finally, <systemitem>init</systemitem> starts &yast;, which starts
      package installation and system configuration.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
</chapter>
